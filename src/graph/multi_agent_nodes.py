# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

import asyncio
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.runnables import RunnableConfig
from langgraph.types import Command

from src.agents import create_agent
from src.config.configuration import Configuration
from src.prompts.planner_model import Plan, Step
from src.tools import get_web_search_tool, crawl_tool, python_repl_tool
from .types import State

logger = logging.getLogger(__name__)


@dataclass
class SubAgentTask:
    """–ó–∞–¥–∞—á–∞ –¥–ª—è —Å—É–±–∞–≥–µ–Ω—Ç–∞ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —Ñ–æ–∫—É—Å–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
    agent_id: str
    research_focus: str  # "market_analysis", "technical_specs", "competitor_research"
    description: str
    tools: List[Any]
    agent_type: str = "researcher"  # NEW: —Ç–∏–ø –∞–≥–µ–Ω—Ç–∞ (researcher|coder)
    context_limit: int = 50000  # –û—Ç–¥–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—É–±–∞–≥–µ–Ω—Ç–∞


@dataclass
class SubAgentResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã —Å—É–±–∞–≥–µ–Ω—Ç–∞ —Å —Å–∂–∞—Ç–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
    agent_id: str
    research_focus: str
    key_findings: str  # –°–∂–∞—Ç—ã–µ –∫–ª—é—á–µ–≤—ã–µ –Ω–∞—Ö–æ–¥–∫–∏
    raw_data: str  # –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    confidence_score: float  # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
    sources: List[str]  # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏


class MultiAgentCoordinator:
    """–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ —Å—É–±–∞–≥–µ–Ω—Ç–∞–º–∏ –ø–æ –æ–±—Ä–∞–∑—Ü—É Anthropic"""
    
    def __init__(self, config: Configuration):
        self.config = config
        self.active_subagents: Dict[str, Any] = {}
        
    async def create_parallel_research_plan(self, query: str, max_subagents: int = 4) -> List[SubAgentTask]:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Å—É–±–∞–≥–µ–Ω—Ç–∞–º–∏
        –ê–Ω–∞–ª–æ–≥ —Å–∏—Å—Ç–µ–º—ã Anthropic –¥–ª—è —Ä–∞–∑–ª–æ–∂–µ–Ω–∏—è –∑–∞–¥–∞—á
        """
        # NEW: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞ –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–±–∞–≥–µ–Ω—Ç–æ–≤
        complexity_score = self._assess_query_complexity(query)
        optimal_subagents = min(max_subagents, max(2, complexity_score))
        
        logger.info(f"üß† Query complexity score: {complexity_score}/5, using {optimal_subagents} subagents")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Å–ø–µ–∫—Ç—ã –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        research_aspects = await self._identify_research_aspects(query, optimal_subagents)
        
        tasks = []
        for i, aspect in enumerate(research_aspects[:optimal_subagents]):
            task = SubAgentTask(
                agent_id=f"subagent_{i}_{aspect['type']}",
                research_focus=aspect['focus'],
                description=aspect['description'],
                tools=self._select_tools_for_aspect(aspect['type']),
                agent_type=self._get_agent_type_for_aspect(aspect['type']),
                context_limit=50000
            )
            tasks.append(task)
            
        logger.info(f"Created {len(tasks)} parallel subagent tasks")
        return tasks
    
    async def execute_parallel_research(self, tasks: List[SubAgentTask], state: State) -> List[SubAgentResult]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å—É–±–∞–≥–µ–Ω—Ç–∞–º–∏
        –ö–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ç–µ–∫—É—â–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã DeerFlow
        """
        logger.info(f"Starting parallel execution of {len(tasks)} subagents")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ—Ä—É—Ç–∏–Ω—ã –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        coroutines = [
            self._execute_subagent_task(task, state) 
            for task in tasks
        ]
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ —Å—É–±–∞–≥–µ–Ω—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*coroutines, return_exceptions=True)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        successful_results = [
            result for result in results 
            if isinstance(result, SubAgentResult)
        ]
        
        logger.info(f"Completed parallel research with {len(successful_results)} successful results")
        return successful_results
    
    async def _execute_subagent_task(self, task: SubAgentTask, state: State) -> SubAgentResult:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é –∑–∞–¥–∞—á—É —Å—É–±–∞–≥–µ–Ω—Ç–∞ –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        –ö–∞–∂–¥—ã–π —Å—É–±–∞–≥–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –∫–∞–∫ —É Anthropic
        """
        logger.info(f"Executing subagent {task.agent_id} for {task.research_focus}")
        
        # –°–æ–∑–¥–∞–µ–º –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Å—É–±–∞–≥–µ–Ω—Ç–∞
        subagent_input = {
            "messages": [
                HumanMessage(
                    content=f"""
                    # Focused Research Task
                    
                    **Research Focus**: {task.research_focus}
                    **Task Description**: {task.description}
                    **Context Limit**: {task.context_limit} tokens
                    
                    Your job is to conduct focused research on this specific aspect and provide:
                    1. Key findings (2-3 most important discoveries)
                    2. Supporting data and evidence
                    3. Source attribution
                    
                    Focus ONLY on your assigned aspect. Other subagents are handling other aspects.
                    Compress your findings into the most essential information.
                    """
                )
            ]
        }
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        agent = create_agent(
            agent_name=task.agent_id,
            agent_type=task.agent_type,
            tools=task.tools,
            prompt_template=task.agent_type
        )
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            result = await agent.ainvoke(
                input=subagent_input,
                config={"recursion_limit": 15}  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≥–ª—É–±–∏–Ω—É –¥–ª—è —Ñ–æ–∫—É—Å–∞
            )
            
            response_content = result["messages"][-1].content
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –Ω–∞—Ö–æ–¥–∫–∏ (–∫–æ–º–ø—Ä–µ—Å—Å–∏—è –∫–∞–∫ —É Anthropic)
            key_findings = await self._compress_findings(response_content, task.research_focus)
            
            return SubAgentResult(
                agent_id=task.agent_id,
                research_focus=task.research_focus,
                key_findings=key_findings,
                raw_data=response_content,
                confidence_score=0.85,  # TODO: –≤—ã—á–∏—Å–ª—è—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
                sources=self._extract_sources(response_content)
            )
            
        except Exception as e:
            logger.error(f"Subagent {task.agent_id} failed: {str(e)}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return SubAgentResult(
                agent_id=task.agent_id,
                research_focus=task.research_focus,
                key_findings=f"Research failed: {str(e)}",
                raw_data="",
                confidence_score=0.0,
                sources=[]
            )
    
    def _assess_query_complexity(self, query: str) -> int:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–±–∞–≥–µ–Ω—Ç–æ–≤ (2-5)
        """
        complexity_indicators = [
            "analyze", "compare", "comprehensive", "detailed", "market", "industry",
            "–∞–Ω–∞–ª–∏–∑", "—Å—Ä–∞–≤–Ω–∏", "–≤—Å–µ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π", "–¥–µ—Ç–∞–ª—å–Ω—ã–π", "—Ä—ã–Ω–æ–∫", "–æ—Ç—Ä–∞—Å–ª—å",
            "research", "investigate", "study", "evaluation", "assessment",
            "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "–∏–∑—É—á–µ–Ω–∏–µ", "–æ—Ü–µ–Ω–∫–∞", "–≤–ª–∏—è–Ω–∏–µ", "—Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏"
        ]
        
        breadth_indicators = [
            "impact", "trends", "future", "current state", "stakeholders",
            "–≤–ª–∏—è–Ω–∏–µ", "—Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏", "–±—É–¥—É—â–µ–µ", "—Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ", "—É—á–∞—Å—Ç–Ω–∏–∫–∏",
            "ecosystem", "landscape", "overview", "multiple", "various",
            "—ç–∫–æ—Å–∏—Å—Ç–µ–º–∞", "–ª–∞–Ω–¥—à–∞—Ñ—Ç", "–æ–±–∑–æ—Ä", "–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π", "—Ä–∞–∑–ª–∏—á–Ω—ã–µ"
        ]
        
        technical_indicators = [
            "technical", "architecture", "implementation", "code", "system",
            "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π", "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞", "—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è", "–∫–æ–¥", "—Å–∏—Å—Ç–µ–º–∞"
        ]
        
        score = 2  # –ë–∞–∑–æ–≤—ã–π —Å—á–µ—Ç –¥–ª—è –ª—é–±–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        
        # +1 –∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        if any(indicator in query.lower() for indicator in complexity_indicators):
            score += 1
            
        # +1 –∑–∞ —à–∏—Ä–æ—Ç—É –æ—Ö–≤–∞—Ç–∞
        if any(indicator in query.lower() for indicator in breadth_indicators):
            score += 1
            
        # +1 –∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã
        if any(indicator in query.lower() for indicator in technical_indicators):
            score += 1
            
        # +1 –∑–∞ –¥–ª–∏–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (–æ–±—ã—á–Ω–æ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ)
        if len(query.split()) > 10:
            score += 1
            
        return min(5, score)  # –ú–∞–∫—Å–∏–º—É–º 5 —Å—É–±–∞–≥–µ–Ω—Ç–æ–≤

    async def _identify_research_aspects(self, query: str, num_agents: int) -> List[Dict[str, str]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∞—Å–ø–µ–∫—Ç—ã –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –ø–æ–¥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–±–∞–≥–µ–Ω—Ç–æ–≤
        """
        # –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤
        all_aspects = [
            {
                "type": "current_state",
                "focus": "Current State Analysis", 
                "description": f"Research the current state, recent developments and latest information about: {query}"
            },
            {
                "type": "historical_context",
                "focus": "Historical Context",
                "description": f"Investigate the historical background, evolution and timeline related to: {query}"
            },
            {
                "type": "stakeholder_analysis", 
                "focus": "Stakeholder Analysis",
                "description": f"Analyze key players, stakeholders, companies and organizations involved in: {query}"
            },
            {
                "type": "technical_specs",
                "focus": "Technical Specifications & Architectures",
                "description": f"Dive deep into technical specifications, architectures or underlying technologies related to: {query}"
            },
            {
                "type": "data_analysis",
                "focus": "Quantitative & Data Analysis",
                "description": f"Perform quantitative analysis, statistics and data-driven insights for: {query}"
            },
            {
                "type": "future_trends",
                "focus": "Future Trends & Implications", 
                "description": f"Research future outlook, trends, predictions and implications for: {query}"
            }
        ]
        
        # –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (2 —Å—É–±–∞–≥–µ–Ω—Ç–∞) - –æ—Å–Ω–æ–≤—ã
        if num_agents == 2:
            return [all_aspects[0], all_aspects[5]]  # current_state + future_trends
            
        # –î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (3 —Å—É–±–∞–≥–µ–Ω—Ç–∞) - –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        elif num_agents == 3:
            return [all_aspects[0], all_aspects[1], all_aspects[5]]  # + historical_context
            
        # –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (4+ —Å—É–±–∞–≥–µ–Ω—Ç–æ–≤) - –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä
        else:
            return all_aspects[:num_agents]
    
    def _select_tools_for_aspect(self, aspect_type: str) -> List[Any]:
        """–í—ã–±–∏—Ä–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ç–∏–ø–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        base_tools = [
            get_web_search_tool(self.config.max_search_results),
            crawl_tool
        ]
        
        if aspect_type in ["current_state", "future_trends", "data_analysis", "technical_specs"]:
            # –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–æ–±–∞–≤–ª—è–µ–º Python REPL
            base_tools.append(python_repl_tool)
            
        return base_tools
    
    def _get_agent_type_for_aspect(self, aspect_type: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∏–ø –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∞—Å–ø–µ–∫—Ç–∞"""
        if aspect_type in ["future_trends", "data_analysis", "technical_specs"]:
            return "coder"
        return "researcher"
    
    async def _compress_findings(self, raw_content: str, focus_area: str) -> str:
        """
        –°–∂–∏–º–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã
        –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –∫–∞–∫ —É Anthropic
        """
        # TODO: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LLM –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–∂–∞—Ç–∏—è
        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è - –ø–µ—Ä–≤—ã–µ N —Å–∏–º–≤–æ–ª–æ–≤ + –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
        
        lines = raw_content.split('\n')
        key_lines = [line for line in lines if any(keyword in line.lower() 
                    for keyword in ['key', 'important', 'finding', 'result', 'conclusion'])]
        
        if key_lines:
            compressed = '\n'.join(key_lines[:5])  # –¢–æ–ø-5 –∫–ª—é—á–µ–≤—ã—Ö —Å—Ç—Ä–æ–∫
        else:
            compressed = raw_content[:1000] + "..." if len(raw_content) > 1000 else raw_content
            
        return f"**{focus_area}**:\n{compressed}"
    
    def _extract_sources(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        import re
        urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', content)
        return list(set(urls))


async def parallel_research_node(state: State, config: RunnableConfig) -> Command:
    """
    –ù–æ–≤—ã–π —É–∑–µ–ª –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ –æ–±—Ä–∞–∑—Ü—É Anthropic
    –ó–∞–º–µ–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ research_team_node
    """
    logger.info("üöÄüöÄüöÄ PARALLEL RESEARCH NODE –ê–ö–¢–ò–í–ò–†–û–í–ê–ù! üöÄüöÄüöÄ")
    logger.info("Starting parallel multi-agent research")
    
    configurable = Configuration.from_runnable_config(config)
    coordinator = MultiAgentCoordinator(configurable)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–ª–∞–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    current_plan = state.get("current_plan")
    if not current_plan or not hasattr(current_plan, 'title'):
        logger.warning("No valid research plan found")
        return Command(goto="reporter")
    
    query = str(current_plan.title)
    logger.info(f"üéØ –ò—Å—Å–ª–µ–¥—É–µ–º: {query}")
    
    # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è  
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è —Å—É–±–∞–≥–µ–Ω—Ç–æ–≤...")
    parallel_tasks = await coordinator.create_parallel_research_plan(
        query, max_subagents=4
    )
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(parallel_tasks)} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á")
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
    logger.info("‚ö° –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å—É–±–∞–≥–µ–Ω—Ç–æ–≤...")
    subagent_results = await coordinator.execute_parallel_research(
        parallel_tasks, state
    )
    logger.info(f"üéâ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ü–æ–ª—É—á–µ–Ω–æ {len(subagent_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —Ä–µ–ø–æ—Ä—Ç–µ—Ä—É
    observations = []
    for result in subagent_results:
        observation = f"""
        ## {result.research_focus}
        
        {result.key_findings}
        
        **Confidence**: {result.confidence_score:.2f}
        **Sources**: {len(result.sources)} sources
        """
        observations.append(observation)
    
    logger.info(f"üìä –ü–µ—Ä–µ–¥–∞–µ–º —Ä–µ–ø–æ—Ä—Ç–µ—Ä—É {len(observations)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞")
    
    return Command(
        update={
            "observations": observations,
            "messages": [
                AIMessage(
                    content=f"Parallel research completed with {len(subagent_results)} specialized investigations",
                    name="multi_agent_coordinator"
                )
            ]
        },
        goto="reporter"
    )


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –≥—Ä–∞—Ñ
def should_use_parallel_research(state: State) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
    –ö—Ä–∏—Ç–µ—Ä–∏–∏: —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞, –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
    """
    current_plan = state.get("current_plan")
    if not current_plan:
        return False
        
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
    steps_attr = getattr(current_plan, 'steps', None)
    if steps_attr and isinstance(steps_attr, list) and len(steps_attr) > 2:
        return True
        
    # –ò–ª–∏ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    query = state.get("research_topic", "").lower()
    complexity_indicators = ["analyze", "compare", "comprehensive", "detailed", "market", "industry"]
    
    return any(indicator in query for indicator in complexity_indicators) 